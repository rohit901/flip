{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "images_root_pth = './birds/CUB_200_2011/images/'\n",
    "text_root_pth = './birds/text/'\n",
    "imgID_pth_df = pd.read_csv('./birds/CUB_200_2011/images.txt', sep=' ', header=None, names=['img_id', 'sub_pth'])\n",
    "train_split_df = pd.read_csv('./birds//CUB_200_2011/train_test_split.txt', sep=' ', names=['img_id', 'is_training'])\n",
    "class_names = pd.read_csv('./birds/CUB_200_2011/classes.txt', sep=' ', header=None, names=['class_id', 'class_name'])\n",
    "class_names.class_name = class_names.class_name.map(lambda x: x.split('.')[1].lower())\n",
    "\n",
    "cub_dataset_df = imgID_pth_df.merge(train_split_df, on='img_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CUBDataset(Dataset):\n",
    "    \"\"\"CUB dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, img_root_dir, text_root_dir, transform=None, t=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Dataframe with paths and train/test split information.\n",
    "            root_dir (string): Root directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.cub_img_df = dataframe\n",
    "        self.img_root_dir = img_root_dir\n",
    "        self.text_root_dir = text_root_dir\n",
    "        self.transform = transform\n",
    "        self.t = t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cub_img_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sub_pth = self.cub_img_df.iloc[idx, 1]\n",
    "        \n",
    "        #IMAGE PROCESSING\n",
    "        img_name = os.path.join(self.img_root_dir,\n",
    "                                sub_pth)\n",
    "        image = io.imread(img_name)\n",
    "        target = int(sub_pth.split('.')[0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        #TEXT PROCESSING\n",
    "        \n",
    "        pth=sub_pth[:-4]+'.txt'\n",
    "        '''\n",
    "        text_file_name = os.path.join(self.text_root_dir, pth)\n",
    "        lines = open(text_file_name).read().splitlines()\n",
    "        content = random.choice(lines)\n",
    "        text = clip.tokenize(content)\n",
    "        \n",
    "        '''\n",
    "        text_file_name = os.path.join(self.text_root_dir, pth)\n",
    "        myfile=open(text_file_name,\"r\")\n",
    "        content=myfile.readline()\n",
    "        text = clip.tokenize(content)\n",
    "        \n",
    "\n",
    "        return image, text, target\n",
    "                                      \n",
    "train_set = CUBDataset(cub_dataset_df[cub_dataset_df.is_training==1],images_root_pth, text_root_pth,transform=transforms.Compose([transforms.ToPILImage(), preprocess]), t=True)\n",
    "test_set = CUBDataset(cub_dataset_df[cub_dataset_df.is_training==0], images_root_pth, text_root_pth, transform=transforms.Compose([transforms.ToPILImage(), preprocess]), t=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5994"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_txt_features(dataset,s1 = None):\n",
    "    all_img_features = []\n",
    "    all_txt_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, details, labels in tqdm(DataLoader(dataset, batch_size=1,shuffle=True, num_workers=0)):\n",
    "            #print(images.shape)\n",
    "            img_features = model.encode_image(images.to(device))\n",
    "            txt_features = model.encode_text(torch.cat(tuple(details)).to(device))\n",
    "\n",
    "            all_img_features.append(img_features)\n",
    "            all_txt_features.append(txt_features)\n",
    "            all_labels.append(labels)\n",
    "    #print(all_img_features.shape)\n",
    "    return all_img_features, all_txt_features, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5994/5994 [02:46<00:00, 35.95it/s]\n",
      "100%|██████████| 5794/5794 [02:28<00:00, 38.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image_features, train_txt_features, train_labels = get_img_txt_features(train_set)\n",
    "test_image_features, test_txt_features, test_labels = get_img_txt_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5994 5994 5994\n",
      "torch.Size([1, 512]) torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image_features), len(train_txt_features), len(train_labels))\n",
    "print(train_image_features[0].shape, train_txt_features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_features = train_image_features.to(torch.float32)\n",
    "train_txt_features = train_txt_features.to(torch.float32) \n",
    "test_image_features = test_image_features.to(torch.float32) \n",
    "test_txt_features = test_txt_features.to(torch.float32)\n",
    "train_labels = train_labels.to(torch.float32) \n",
    "train_labels = train_labels.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_temp = torch.cat(train_image_features, axis=0)\n",
    "txt_temp = torch.cat(train_txt_features, axis=0)\n",
    "labels_temp = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5994, 512])\n"
     ]
    }
   ],
   "source": [
    "print(txt_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessedDataset(Dataset):\n",
    "    def __init__(self, image_features, text_features, classes, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Dataframe with paths and train/test split information.\n",
    "            root_dir (string): Root directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.image_features = image_features\n",
    "        self.text_features = text_features\n",
    "        self.transform = transform\n",
    "        self.labels = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        image_feature = self.image_features[idx]\n",
    "        text_feature = self.text_features[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "\n",
    "        return image_feature, text_feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pset = ProcessedDataset(train_image_features, train_txt_features, train_labels)\n",
    "test_pset = ProcessedDataset(test_image_features, test_txt_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_pset, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_pset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_Model(\n",
      "  (img_hid1): Linear(in_features=512, out_features=384, bias=True)\n",
      "  (img_hid3): Linear(in_features=384, out_features=256, bias=True)\n",
      "  (img_hid4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (img_dropout1): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#image model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Image_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Image_Model, self).__init__()\n",
    "        self.img_hid1 = nn.Linear(512, 384)\n",
    "        #self.img_hid2 = nn.Linear(256, 256)\n",
    "        self.img_hid3 = nn.Linear(384, 256)\n",
    "        self.img_hid4 = nn.Linear(256, 128)\n",
    "        self.img_dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, img):\n",
    "        z1 = F.relu(self.img_hid1(img))\n",
    "        z1 = self.img_dropout1(z1)\n",
    "        #z1 = F.relu(self.img_hid2(z1))\n",
    "        z1 = F.relu(self.img_hid3(z1))\n",
    "        z1 = F.relu(self.img_hid4(z1))\n",
    "        # print(z1.shape)\n",
    "        return z1\n",
    "\n",
    "img_model = Image_Model()\n",
    "print(img_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text_Model(\n",
      "  (txt_hid1): Linear(in_features=512, out_features=384, bias=True)\n",
      "  (txt_hid3): Linear(in_features=384, out_features=256, bias=True)\n",
      "  (txt_hid4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (txt_dropout1): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#text model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Text_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Text_Model, self).__init__()\n",
    "        self.txt_hid1 = nn.Linear(512, 384)\n",
    "        #self.txt_hid2 = nn.Linear(256, 256)\n",
    "        self.txt_hid3 = nn.Linear(384, 256)\n",
    "        self.txt_hid4 = nn.Linear(256, 128)\n",
    "        self.txt_dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, text):\n",
    "        z2 = F.relu(self.txt_hid1(text))\n",
    "        z2 = self.txt_dropout1(z2)\n",
    "        #z2 = F.relu(self.txt_hid2(z2))\n",
    "        z2 = F.relu(self.txt_hid3(z2))\n",
    "        z2 = F.relu(self.txt_hid4(z2))\n",
    "        # print(z2.shape)\n",
    "        return z2\n",
    "\n",
    "txt_model = Text_Model()\n",
    "print(txt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParentModel(\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=200, bias=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ParentModel(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(ParentModel, self).__init__()\n",
    "        # self.modelA = modelA\n",
    "        # self.modelB = modelB\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512,200)\n",
    "        # self.fc3 = nn.Linear(64,200)\n",
    "         \n",
    "        self.dropout1=nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1 = self.modelA(x1)\n",
    "        # x2 = self.modelB(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x=x.float()\n",
    "        # print(x.shape)\n",
    "        x=self.bn1(F.relu(self.fc1(x)))\n",
    "        x=self.fc2(x)\n",
    "        # x = self.dropout1(x)\n",
    "        # x=self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "img_model = Image_Model()\n",
    "txt_model = Text_Model()\n",
    "end_model = ParentModel(img_model, txt_model)\n",
    "print(end_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 628424\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in end_model.parameters())\n",
    "print('Number of parameters: {0}'.format(pytorch_total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "end_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.SGD(end_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 426.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 4.4453 accuracy: 14.8815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1517.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.5573 accuracy: 35.7957\n",
      "epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 524.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 3.0383 accuracy: 49.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1564.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.8232 accuracy: 41.9572\n",
      "epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 423.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 2.2798 accuracy: 65.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1574.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.1375 accuracy: 62.0642\n",
      "epoch number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 411.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.8066 accuracy: 74.2075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1522.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.8186 accuracy: 66.5516\n",
      "epoch number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 426.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.4756 accuracy: 79.7965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1551.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.6057 accuracy: 69.3649\n",
      "epoch number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 445.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.2536 accuracy: 82.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1569.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.4670 accuracy: 71.0045\n",
      "epoch number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 435.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.0805 accuracy: 86.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1567.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.3519 accuracy: 72.2644\n",
      "epoch number: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 455.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.9438 accuracy: 87.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1633.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.2688 accuracy: 73.0929\n",
      "epoch number: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 445.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.8407 accuracy: 89.3560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1547.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.2083 accuracy: 73.5243\n",
      "epoch number: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 411.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.7441 accuracy: 91.2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1532.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.1665 accuracy: 73.6624\n",
      "epoch number: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 437.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.6669 accuracy: 92.1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1558.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.1387 accuracy: 73.7142\n",
      "epoch number: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 453.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.6015 accuracy: 93.4101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1317.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0905 accuracy: 74.4736\n",
      "epoch number: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 481.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.5442 accuracy: 94.4611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1519.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0742 accuracy: 74.3528\n",
      "epoch number: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 435.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.4887 accuracy: 95.4454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1492.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0577 accuracy: 74.4736\n",
      "epoch number: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 443.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.4518 accuracy: 95.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1523.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0570 accuracy: 73.9903\n",
      "epoch number: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 405.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.4089 accuracy: 96.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1514.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0379 accuracy: 74.1111\n",
      "epoch number: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 425.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.3804 accuracy: 97.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1497.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0330 accuracy: 74.2320\n",
      "epoch number: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 404.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.3489 accuracy: 97.4975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1525.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0124 accuracy: 74.0421\n",
      "epoch number: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 466.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.3166 accuracy: 98.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1592.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0109 accuracy: 74.5944\n",
      "epoch number: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 403.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2880 accuracy: 98.4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1481.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0088 accuracy: 74.1457\n",
      "epoch number: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 442.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2735 accuracy: 98.7821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1537.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0000 accuracy: 73.8523\n",
      "epoch number: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 465.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2482 accuracy: 99.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1549.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0016 accuracy: 74.1974\n",
      "epoch number: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 390.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2287 accuracy: 99.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1510.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0036 accuracy: 73.5934\n",
      "epoch number: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 437.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2108 accuracy: 99.3994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1595.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9879 accuracy: 73.9213\n",
      "epoch number: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 457.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.1969 accuracy: 99.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1545.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9996 accuracy: 73.9386\n",
      "epoch number: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 465.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.1840 accuracy: 99.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1422.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9860 accuracy: 74.0594\n",
      "epoch number: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 430.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.1723 accuracy: 99.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1503.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9845 accuracy: 73.9558\n",
      "epoch number: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 430.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.1603 accuracy: 99.8665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1478.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9778 accuracy: 73.3690\n",
      "epoch number: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 492.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.1506 accuracy: 99.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1498.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9800 accuracy: 73.7832\n",
      "epoch number: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 458.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.1402 accuracy: 99.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1561.27batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9806 accuracy: 73.4898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=30\n",
    "\n",
    "end_model.to(device)\n",
    "for epoch in range(0, epochs):\n",
    "    train_loss=0\n",
    "    test_loss=0\n",
    "    train_total=0\n",
    "    train_correct=0\n",
    "    \n",
    "    print(\"epoch number: {0}\".format(epoch))\n",
    "    end_model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "\n",
    "        for batch_idx, (train_images, train_details, train_labels) in enumerate(tepoch):\n",
    "            \n",
    "            train_img_features = torch.cat(tuple(train_images)).to(device)\n",
    "            train_txt_features = torch.cat(tuple(train_details)).to(device)\n",
    "            #print(img_features.shape, txt_features.shape)\n",
    "            \n",
    "            #print(train_labels)\n",
    "            train_labels = torch.cat(tuple(train_labels)).to(device)\n",
    "            #print(train_labels.shape)\n",
    "            optimizer.zero_grad()\n",
    "            output = end_model(train_img_features, train_txt_features)\n",
    "            #print(output)\n",
    "            loss = criterion(output, train_labels.long()-1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            train_total += train_labels.size(0)\n",
    "            train_correct += predicted.eq(train_labels.long()-1).sum().item()\n",
    "            # print(train_correct) \n",
    "        print(' train loss: {:.4f} accuracy: {:.4f}'.format(train_loss/(batch_idx+1), 100.*train_correct/train_total))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_total=0\n",
    "        test_correct= 0\n",
    "        \n",
    "        end_model.eval()\n",
    "        \n",
    "        with tqdm(test_loader, unit =\"batch\") as tepoch:\n",
    "            for batch_idx ,(text_images, test_details, test_labels) in enumerate(tepoch):\n",
    "\n",
    "\n",
    "                test_img_features = torch.cat(tuple(text_images)).to(device)\n",
    "                test_txt_features = torch.cat(tuple(test_details)).to(device)\n",
    "                test_labels = torch.cat(tuple(test_labels)).to(device)\n",
    "\n",
    "                y_pred_test = end_model(test_img_features, test_txt_features)\n",
    "                loss_test = criterion(y_pred_test, test_labels.long()-1)\n",
    "                test_loss+=loss_test.item()\n",
    "            \n",
    "                _, predicted = y_pred_test.max(1)\n",
    "                test_total += test_labels.size(0)\n",
    "                test_correct += predicted.eq(test_labels.long()-1).sum().item()\n",
    "            print('test loss: {:.4f} accuracy: {:.4f}'.format(test_loss/(batch_idx+1), 100.*test_correct/test_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch number: 11\n",
    "# 100%|██████████| 375/375 [00:00<00:00, 453.72batch/s]\n",
    "#  train loss: 0.6015 accuracy: 93.4101\n",
    "# 100%|██████████| 363/363 [00:00<00:00, 1317.24batch/s]\n",
    "# test loss: 1.0905 accuracy: 74.4736\n",
    "# epoch number: 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('AIproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "735e3d6a9ddcdeadb22423071002d0111a5f94a8e66fbb853e08ee6520688969"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
