{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CLIP's image encoder for feature extraction, training all the images and the 512 dimension embedding is used for training the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4076287/3077369022.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  whole_df=whole_df.append(whole, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>sub_pth</th>\n",
       "      <th>is_training</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>11778</td>\n",
       "      <td>200.Common_Yellowthroat/Common_Yellowthroat_00...</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>11781</td>\n",
       "      <td>200.Common_Yellowthroat/Common_Yellowthroat_00...</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>11782</td>\n",
       "      <td>200.Common_Yellowthroat/Common_Yellowthroat_00...</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>11784</td>\n",
       "      <td>200.Common_Yellowthroat/Common_Yellowthroat_00...</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>11787</td>\n",
       "      <td>200.Common_Yellowthroat/Common_Yellowthroat_00...</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5994 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_id                                            sub_pth is_training  \\\n",
       "0         2  001.Black_footed_Albatross/Black_Footed_Albatr...           1   \n",
       "1         4  001.Black_footed_Albatross/Black_Footed_Albatr...           1   \n",
       "2         5  001.Black_footed_Albatross/Black_Footed_Albatr...           1   \n",
       "3         7  001.Black_footed_Albatross/Black_Footed_Albatr...           1   \n",
       "4         8  001.Black_footed_Albatross/Black_Footed_Albatr...           1   \n",
       "...     ...                                                ...         ...   \n",
       "5989  11778  200.Common_Yellowthroat/Common_Yellowthroat_00...           1   \n",
       "5990  11781  200.Common_Yellowthroat/Common_Yellowthroat_00...           1   \n",
       "5991  11782  200.Common_Yellowthroat/Common_Yellowthroat_00...           1   \n",
       "5992  11784  200.Common_Yellowthroat/Common_Yellowthroat_00...           1   \n",
       "5993  11787  200.Common_Yellowthroat/Common_Yellowthroat_00...           1   \n",
       "\n",
       "     class  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "...    ...  \n",
       "5989   200  \n",
       "5990   200  \n",
       "5991   200  \n",
       "5992   200  \n",
       "5993   200  \n",
       "\n",
       "[5994 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_pth = './birds/CUB_200_2011/images/'\n",
    "imgID_pth_df = pd.read_csv('./birds/CUB_200_2011/images.txt', sep=' ', header=None, names=['img_id', 'sub_pth'])\n",
    "train_split_df = pd.read_csv('./birds/CUB_200_2011/train_test_split.txt', sep=' ', names=['img_id', 'is_training'])\n",
    "class_names = pd.read_csv('./birds/CUB_200_2011/classes.txt', sep=' ', header=None, names=['class_id', 'class_name'])\n",
    "class_names.class_name = class_names.class_name.map(lambda x: x.split('.')[1].lower())\n",
    "\n",
    "cub_dataset_df = imgID_pth_df.merge(train_split_df, on='img_id', how='inner')\n",
    "\n",
    "\n",
    "target=[]\n",
    "for pth in cub_dataset_df['sub_pth']:\n",
    "    target.append(int(pth.split('.')[0]))\n",
    "df = pd.DataFrame(target, columns=['class'])\n",
    "train_df=cub_dataset_df[cub_dataset_df.is_training==1]\n",
    "final_df = train_df.join(df)\n",
    "\n",
    "whole_df=pd.DataFrame(columns=['img_id', 'sub_pth', 'is_training', 'class'])\n",
    "for i in range(1,201):\n",
    "    whole=final_df[final_df['class']==i]\n",
    "    whole_df=whole_df.append(whole, ignore_index=True)\n",
    "\n",
    "whole_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CUBDataset(Dataset):\n",
    "    \"\"\"CUB dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Dataframe with paths and train/test split information.\n",
    "            root_dir (string): Root directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.cub_img_df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cub_img_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sub_pth = self.cub_img_df.iloc[idx, 1]\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                sub_pth)\n",
    "        image = io.imread(img_name)\n",
    "        target = int(sub_pth.split('.')[0])#.split('.')[1].lower()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n",
    "\n",
    "# loading CUB-200-2011 train&test dataset\n",
    "train_set = CUBDataset(whole_df, root_pth, transform=transforms.Compose([transforms.ToPILImage(), preprocess]))\n",
    "test_set = CUBDataset(cub_dataset_df[cub_dataset_df.is_training==0], root_pth, transform=transforms.Compose([transforms.ToPILImage(), preprocess]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=16,shuffle=True)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "            #features /= features.norm(dim=-1, keepdim=True)\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:03<00:00,  5.90it/s]\n",
      "100%|██████████| 363/363 [00:59<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = get_features(train_set)\n",
    "test_features, test_labels = get_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5994, 512) (5794, 512)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santosh.sanjeev/.conda/envs/AIproject/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/tmp/ipykernel_4076287/2153442391.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic = 74.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4076287/2153442391.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN= 57.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4076287/2153442391.py:22: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM-Linear= 72.938\n",
      "Accuracy SVM-RBF= 71.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4076287/2153442391.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_features, train_labels)\n",
    "predictions = classifier.predict(test_features)\n",
    "\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy Logistic = {accuracy:.3f}\")\n",
    "\n",
    "from sklearn import neighbors\n",
    "clf=neighbors.KNeighborsClassifier()\n",
    "clf.fit(train_features, train_labels)\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy KNN= {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "scl=SVC(kernel='linear')\n",
    "scl.fit(train_features, train_labels)\n",
    "predictions = scl.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy SVM-Linear= {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "sc=SVC(kernel='rbf')\n",
    "sc.fit(train_features, train_labels)\n",
    "predictions = sc.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy SVM-RBF= {accuracy:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('AIproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "735e3d6a9ddcdeadb22423071002d0111a5f94a8e66fbb853e08ee6520688969"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
