{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "checkpoint = torch.load(\"./model_30_5e7_001_fixed.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "images_root_pth = './birds/CUB_200_2011/images/'\n",
    "text_root_pth = './birds/text/'\n",
    "imgID_pth_df = pd.read_csv('./birds/CUB_200_2011/images.txt', sep=' ', header=None, names=['img_id', 'sub_pth'])\n",
    "train_split_df = pd.read_csv('./birds//CUB_200_2011/train_test_split.txt', sep=' ', names=['img_id', 'is_training'])\n",
    "class_names = pd.read_csv('./birds/CUB_200_2011/classes.txt', sep=' ', header=None, names=['class_id', 'class_name'])\n",
    "class_names.class_name = class_names.class_name.map(lambda x: x.split('.')[1].lower())\n",
    "\n",
    "cub_dataset_df = imgID_pth_df.merge(train_split_df, on='img_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CUBDataset(Dataset):\n",
    "    \"\"\"CUB dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, img_root_dir, text_root_dir, transform=None, t=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Dataframe with paths and train/test split information.\n",
    "            root_dir (string): Root directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.cub_img_df = dataframe\n",
    "        self.img_root_dir = img_root_dir\n",
    "        self.text_root_dir = text_root_dir\n",
    "        self.transform = transform\n",
    "        self.t = t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cub_img_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sub_pth = self.cub_img_df.iloc[idx, 1]\n",
    "        \n",
    "        #IMAGE PROCESSING\n",
    "        img_name = os.path.join(self.img_root_dir,\n",
    "                                sub_pth)\n",
    "        image = io.imread(img_name)\n",
    "        target = int(sub_pth.split('.')[0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        #TEXT PROCESSING\n",
    "        \n",
    "        pth=sub_pth[:-4]+'.txt'\n",
    "        '''\n",
    "        text_file_name = os.path.join(self.text_root_dir, pth)\n",
    "        lines = open(text_file_name).read().splitlines()\n",
    "        content = random.choice(lines)\n",
    "        text = clip.tokenize(content)\n",
    "        \n",
    "        '''\n",
    "        text_file_name = os.path.join(self.text_root_dir, pth)\n",
    "        myfile=open(text_file_name,\"r\")\n",
    "        content=myfile.readline()\n",
    "        text = clip.tokenize(content)\n",
    "        \n",
    "\n",
    "        return image, text, target\n",
    "                                      \n",
    "train_set = CUBDataset(cub_dataset_df[cub_dataset_df.is_training==1],images_root_pth, text_root_pth,transform=transforms.Compose([transforms.ToPILImage(), preprocess]), t=True)\n",
    "test_set = CUBDataset(cub_dataset_df[cub_dataset_df.is_training==0], images_root_pth, text_root_pth, transform=transforms.Compose([transforms.ToPILImage(), preprocess]), t=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5994"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_txt_features(dataset,s1 = None):\n",
    "    all_img_features = []\n",
    "    all_txt_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, details, labels in tqdm(DataLoader(dataset, batch_size=1,shuffle=True, num_workers=0)):\n",
    "            #print(images.shape)\n",
    "            img_features = model.encode_image(images.to(device))\n",
    "            txt_features = model.encode_text(torch.cat(tuple(details)).to(device))\n",
    "\n",
    "            all_img_features.append(img_features)\n",
    "            all_txt_features.append(txt_features)\n",
    "            all_labels.append(labels)\n",
    "    #print(all_img_features.shape)\n",
    "    return all_img_features, all_txt_features, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5994/5994 [02:31<00:00, 39.66it/s]\n",
      "100%|██████████| 5794/5794 [02:37<00:00, 36.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image_features, train_txt_features, train_labels = get_img_txt_features(train_set)\n",
    "test_image_features, test_txt_features, test_labels = get_img_txt_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5994 5994 5994\n",
      "torch.Size([1, 512]) torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image_features), len(train_txt_features), len(train_labels))\n",
    "print(train_image_features[0].shape, train_txt_features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_image_features \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_image_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      2\u001b[0m train_txt_features \u001b[38;5;241m=\u001b[39m train_txt_features\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32) \n\u001b[1;32m      3\u001b[0m test_image_features \u001b[38;5;241m=\u001b[39m test_image_features\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "train_image_features = train_image_features.to(torch.float32)\n",
    "train_txt_features = train_txt_features.to(torch.float32) \n",
    "test_image_features = test_image_features.to(torch.float32) \n",
    "test_txt_features = test_txt_features.to(torch.float32)\n",
    "train_labels = train_labels.to(torch.float32) \n",
    "train_labels = train_labels.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_temp = torch.cat(train_image_features, axis=0)\n",
    "txt_temp = torch.cat(train_txt_features, axis=0)\n",
    "labels_temp = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5994, 512])\n"
     ]
    }
   ],
   "source": [
    "print(txt_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessedDataset(Dataset):\n",
    "    def __init__(self, image_features, text_features, classes, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Dataframe with paths and train/test split information.\n",
    "            root_dir (string): Root directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.image_features = image_features\n",
    "        self.text_features = text_features\n",
    "        self.transform = transform\n",
    "        self.labels = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        image_feature = self.image_features[idx]\n",
    "        text_feature = self.text_features[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "\n",
    "        return image_feature, text_feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pset = ProcessedDataset(train_image_features, train_txt_features, train_labels)\n",
    "test_pset = ProcessedDataset(test_image_features, test_txt_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_pset, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_pset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_Model(\n",
      "  (img_hid1): Linear(in_features=512, out_features=384, bias=True)\n",
      "  (img_hid3): Linear(in_features=384, out_features=256, bias=True)\n",
      "  (img_hid4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (img_dropout1): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#image model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Image_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Image_Model, self).__init__()\n",
    "        self.img_hid1 = nn.Linear(512, 384)\n",
    "        #self.img_hid2 = nn.Linear(256, 256)\n",
    "        self.img_hid3 = nn.Linear(384, 256)\n",
    "        self.img_hid4 = nn.Linear(256, 128)\n",
    "        self.img_dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, img):\n",
    "        z1 = F.relu(self.img_hid1(img))\n",
    "        z1 = self.img_dropout1(z1)\n",
    "        #z1 = F.relu(self.img_hid2(z1))\n",
    "        z1 = F.relu(self.img_hid3(z1))\n",
    "        z1 = F.relu(self.img_hid4(z1))\n",
    "        # print(z1.shape)\n",
    "        return z1\n",
    "\n",
    "img_model = Image_Model()\n",
    "print(img_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text_Model(\n",
      "  (txt_hid1): Linear(in_features=512, out_features=384, bias=True)\n",
      "  (txt_hid3): Linear(in_features=384, out_features=256, bias=True)\n",
      "  (txt_hid4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (txt_dropout1): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#text model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Text_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Text_Model, self).__init__()\n",
    "        self.txt_hid1 = nn.Linear(512, 384)\n",
    "        #self.txt_hid2 = nn.Linear(256, 256)\n",
    "        self.txt_hid3 = nn.Linear(384, 256)\n",
    "        self.txt_hid4 = nn.Linear(256, 128)\n",
    "        self.txt_dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, text):\n",
    "        z2 = F.relu(self.txt_hid1(text))\n",
    "        z2 = self.txt_dropout1(z2)\n",
    "        #z2 = F.relu(self.txt_hid2(z2))\n",
    "        z2 = F.relu(self.txt_hid3(z2))\n",
    "        z2 = F.relu(self.txt_hid4(z2))\n",
    "        # print(z2.shape)\n",
    "        return z2\n",
    "\n",
    "txt_model = Text_Model()\n",
    "print(txt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParentModel(\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=200, bias=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ParentModel(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(ParentModel, self).__init__()\n",
    "        # self.modelA = modelA\n",
    "        # self.modelB = modelB\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512,200)\n",
    "        # self.fc3 = nn.Linear(64,200)\n",
    "         \n",
    "        self.dropout1=nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1 = self.modelA(x1)\n",
    "        # x2 = self.modelB(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        # print(x.shape)\n",
    "        x=x.float()\n",
    "        x=self.bn1(F.relu(self.fc1(x)))\n",
    "        x=self.fc2(x)\n",
    "        # x = self.dropout1(x)\n",
    "        # x=self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "img_model = Image_Model()\n",
    "txt_model = Text_Model()\n",
    "end_model = ParentModel(img_model, txt_model)\n",
    "print(end_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 628424\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in end_model.parameters())\n",
    "print('Number of parameters: {0}'.format(pytorch_total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "end_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.SGD(end_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 411.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 4.4226 accuracy: 15.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1563.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.5561 accuracy: 34.9154\n",
      "epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 392.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 3.1261 accuracy: 46.5465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1566.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.7639 accuracy: 51.2254\n",
      "epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 344.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 2.4216 accuracy: 62.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1515.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.2511 accuracy: 59.3200\n",
      "epoch number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 473.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.9570 accuracy: 71.5048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1592.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.9502 accuracy: 65.1709\n",
      "epoch number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 378.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.6281 accuracy: 77.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1620.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.7080 accuracy: 69.4166\n",
      "epoch number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 340.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.3851 accuracy: 80.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1514.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.5496 accuracy: 70.7283\n",
      "epoch number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 337.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.2051 accuracy: 83.4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1605.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.4197 accuracy: 71.9020\n",
      "epoch number: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 327.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 1.0594 accuracy: 84.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1559.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.3318 accuracy: 73.1446\n",
      "epoch number: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 328.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.9390 accuracy: 87.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1576.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.2716 accuracy: 73.8523\n",
      "epoch number: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 337.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.8517 accuracy: 89.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1556.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.2245 accuracy: 73.8177\n",
      "epoch number: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 334.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.7775 accuracy: 89.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1583.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.1898 accuracy: 73.6279\n",
      "epoch number: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 340.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.7052 accuracy: 91.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1579.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.1506 accuracy: 74.4909\n",
      "epoch number: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 350.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.6432 accuracy: 92.4758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1582.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.1206 accuracy: 74.3183\n",
      "epoch number: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 342.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.5898 accuracy: 93.1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1578.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.1000 accuracy: 74.4391\n",
      "epoch number: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 332.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.5466 accuracy: 94.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1578.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0769 accuracy: 75.1812\n",
      "epoch number: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 383.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.5030 accuracy: 95.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1586.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0708 accuracy: 74.4391\n",
      "epoch number: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 468.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.4761 accuracy: 95.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1550.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0652 accuracy: 74.5254\n",
      "epoch number: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 457.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.4444 accuracy: 95.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1461.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0656 accuracy: 74.7670\n",
      "epoch number: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 465.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.4133 accuracy: 96.6133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1270.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0576 accuracy: 74.7152\n",
      "epoch number: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 430.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.3818 accuracy: 97.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1572.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0414 accuracy: 74.0594\n",
      "epoch number: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 376.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.3595 accuracy: 97.6310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1537.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0325 accuracy: 74.1111\n",
      "epoch number: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 459.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.3285 accuracy: 98.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1554.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0356 accuracy: 73.7832\n",
      "epoch number: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 455.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.3085 accuracy: 98.1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1562.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0213 accuracy: 74.1974\n",
      "epoch number: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 444.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2921 accuracy: 98.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1303.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0183 accuracy: 74.4736\n",
      "epoch number: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 419.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2739 accuracy: 98.6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1512.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0273 accuracy: 73.8523\n",
      "epoch number: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 493.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2594 accuracy: 99.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1528.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0242 accuracy: 73.9731\n",
      "epoch number: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 387.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2468 accuracy: 99.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1517.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0319 accuracy: 73.4898\n",
      "epoch number: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 420.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2322 accuracy: 99.2993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1583.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0173 accuracy: 73.9731\n",
      "epoch number: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 432.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2204 accuracy: 99.3994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1553.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0244 accuracy: 73.8350\n",
      "epoch number: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 420.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 0.2044 accuracy: 99.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1566.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0164 accuracy: 73.8177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=30\n",
    "\n",
    "end_model.to(device)\n",
    "for epoch in range(0, epochs):\n",
    "    train_loss=0\n",
    "    test_loss=0\n",
    "    train_total=0\n",
    "    train_correct=0\n",
    "    \n",
    "    print(\"epoch number: {0}\".format(epoch))\n",
    "    end_model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "\n",
    "        for batch_idx, (train_images, train_details, train_labels) in enumerate(tepoch):\n",
    "            \n",
    "            train_img_features = torch.cat(tuple(train_images)).to(device)\n",
    "            train_txt_features = torch.cat(tuple(train_details)).to(device)\n",
    "            #print(img_features.shape, txt_features.shape)\n",
    "            \n",
    "            #print(train_labels)\n",
    "            train_labels = torch.cat(tuple(train_labels)).to(device)\n",
    "            #print(train_labels.shape)\n",
    "            optimizer.zero_grad()\n",
    "            output = end_model(train_img_features, train_txt_features)\n",
    "            #print(output)\n",
    "            loss = criterion(output, train_labels.long()-1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            train_total += train_labels.size(0)\n",
    "            train_correct += predicted.eq(train_labels.long()-1).sum().item()\n",
    "            # print(train_correct) \n",
    "        print(' train loss: {:.4f} accuracy: {:.4f}'.format(train_loss/(batch_idx+1), 100.*train_correct/train_total))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_total=0\n",
    "        test_correct= 0\n",
    "        \n",
    "        end_model.eval()\n",
    "        \n",
    "        with tqdm(test_loader, unit =\"batch\") as tepoch:\n",
    "            for batch_idx ,(text_images, test_details, test_labels) in enumerate(tepoch):\n",
    "\n",
    "\n",
    "                test_img_features = torch.cat(tuple(text_images)).to(device)\n",
    "                test_txt_features = torch.cat(tuple(test_details)).to(device)\n",
    "                test_labels = torch.cat(tuple(test_labels)).to(device)\n",
    "\n",
    "                y_pred_test = end_model(test_img_features, test_txt_features)\n",
    "                loss_test = criterion(y_pred_test, test_labels.long()-1)\n",
    "                test_loss+=loss_test.item()\n",
    "            \n",
    "                _, predicted = y_pred_test.max(1)\n",
    "                test_total += test_labels.size(0)\n",
    "                test_correct += predicted.eq(test_labels.long()-1).sum().item()\n",
    "            print('test loss: {:.4f} accuracy: {:.4f}'.format(test_loss/(batch_idx+1), 100.*test_correct/test_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch number: 14\n",
    "# 100%|██████████| 375/375 [00:01<00:00, 332.91batch/s]\n",
    "#  train loss: 0.5466 accuracy: 94.1441\n",
    "# 100%|██████████| 363/363 [00:00<00:00, 1578.79batch/s]\n",
    "# test loss: 1.0769 accuracy: 75.1812\n",
    "# epoch number: 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('AIproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "735e3d6a9ddcdeadb22423071002d0111a5f94a8e66fbb853e08ee6520688969"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
